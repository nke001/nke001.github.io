<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<!-- saved from url=(0041)https://people.eecs.berkeley.edu/~barron/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    heading2 {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 18px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 42px;
    }
    li:not(:last-child) {
        margin-bottom: 5px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <title>Nan Rosemary Ke</title>

  <link href="./_files/css" rel="stylesheet" type="text/css">
  <style id="dark-reader-style" type="text/css">@media screen {

/* Leading rule */
html {
  -webkit-filter: brightness(110%) contrast(90%) grayscale(20%) sepia(10%) !important;
}

/* Text contrast */
html {
  text-shadow: 0 0 0 !important;
}

/* Full screen */
*:-webkit-full-screen, *:-webkit-full-screen * {
  -webkit-filter: none !important;
}

/* Page background */
html {
  background: rgb(255,255,255) !important;
}

}</style></head>
  <body><div id="StayFocusd-infobar" style="display: none; top: 2400px;">
    <img src="chrome-extension://laankejkbhbdhmipfmgcngdelahlfoji/common/img/eye_19x19_red.png">
    <span id="StayFocusd-infobar-msg"></span>
    <span id="StayFocusd-infobar-links">
        <a id="StayFocusd-infobar-never-show">hide forever</a>&nbsp;&nbsp;|&nbsp;&nbsp;
        <a id="StayFocusd-infobar-hide">hide once</a>
    </span>
</div>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tbody><tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td width="67%" valign="middle">
        <p align="center">
        <name>Nan Rosemary Ke</name><br>
        nan.rosemary.ke at gmail dot com
        </p>
        <p>I am a second year PhD student at <a href="www.umontreal.ca/">University of Montreal</a>. I am a part
        of <a href="http://mila.umontreal.ca">MILA</a>, advised by Professor Chris Pal
        </p>
        <p>
        I am interested in new ways of training Recurrent Neural Networks, generative models and causal inference learning. I also spend time at Microsoft Research Maluuba, where I work on improved RNN training, generative models and language related research.
        Prior to joining MILA, I received my undergraduate degree in Computer Science at the University of Auckland, after which I spent time at Carnegie Mellon University, working on Speech Recognition research.
     
        </p>
        <p align="center">
<a href="https://scholar.google.ca/citations?user=dxwPYhQAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
<a href="https://github.com/nke001"> GitHub </a>
        </p>
        </td>
        <td  width=250 height=250>
        <img src="./files/img.jpg"  width=250 height=250>
        </td>
      </tr>
  </tbody></table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr><td>
            <heading>News</heading>
            <ul>
              <li> At <a href="www.iclr.cc">ICLR 2018</a>, I helped to  co-organize the <a href="http://www.cs.mcgill.ca/~jpineau/ICLR2018-ReproducibilityChallenge.html">ICLR Reproducibility Challenge</a>.</li>  
              <li> At <a href="https://icml.cc/Conferences/2017/">ICML 2017</a>, I helped to co-organize a workshop <a href="https://sites.google.com/view/icml-reproducibility-workshop/home">Workshop on Reproducibility in Machine Learning</a>.</li>
              <li> At <a href="https://mila.quebec/en/cours/deep-learning-summer-school-2017/">Deep Learning and Reinforcement Learning Summer School</a>, I founded and organized the <a href="">Women in Deep Learning Workshop,</a>.</li> 
            </ul>
        </td></tr>

        <tr><td>
            <heading>Talks</heading>
            <ul>
                <li> In Oct 2017, I gave a talk on my work: ”Twin Networks: Using the Future to generate sequences” <a href="https://openreview.net/pdf?id=BydLzGb0Z"></a></li>
              <li> In Sep 2017, I gave a talk on my work: ””Hierachical Attention for sequence to sequence networks” at the Deep Language Workshop organized by MILA and Microsoft Research</a>. </li>

            </ul>
        </td></tr>

      <tr>
        <td width="100%" valign="middle">
          <heading>Research</heading>
          <p>
          These days, most of my time goes in thinking how my brain does efficient credit assignment in time ? 
          For RL problems, I'd like to figure out a method that estimates the gradient of the reward with respect
          to the action probabilities in a way that mimics some of the fundamental properties of
          backprop. Backprop works by *composing* local estimates of effects (Jacobians).
          In general I'm interested in generative models, overcoming catestrophoc forgetting in neural networks, 
          credit assignment in discrete action space.  

          </p>

        </td>
      </tr>
     </tbody></table>

     <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

       <!--
        <tr onmouseout="maml_stop()" onmouseover="maml_start()">
          <td width="25%">
            <heading2><i>Recent Preprints</i></heading2><br><br>
            <div class="one">
                <div class="two" id="maml_image" style="opacity: 0;"><img src="./_files/maml_diagram.png" width=150 height=140></div>
                <img src="./_files/maml_diagram.png" width=150 height=140>
            </div>
            <script type="text/javascript">
            function maml_start() {
              document.getElementById('maml_image').style.opacity = "1";
            }
   function maml_stop() {
              document.getElementById('maml_image').style.opacity = "0";
            }
            maml_stop()
            </script>

              </td>
              <td valign="top" width="75%">
                <heading2><i></i></heading2><br>
              <p><a href="https://arxiv.org/pdf/1703.03400.pdf">
                <papertitle>Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks</papertitle></a><br>
              <strong>Chelsea Finn</strong>,
              <a href="http://people.eecs.berkeley.edu/~pabbeel">Pieter Abbeel</a>,
              <a href="http://people.eecs.berkeley.edu/~svlevine">Sergey Levine</a> <br>
                <a href="https://arxiv.org/abs/1703.03400">arXiv</a>
                /
                <a href="https://github.com/cbfinn/maml">code</a>
                /
                <a href="https://sites.google.com/view/maml">video results</a>
              </p><p></p>
              <p> We propose a model-agnostic algorithm for meta-learning, where a model's parameters
              are trained such that a small number of gradient updates with a small amount of training data from a new task
              will produce good generalization performance on that task. Our method learns a classifier that can recognize
              images of new characters using only a few examples, and a policy that can rapidly adapt
              its behavior in simulated locomotion tasks.


              </p>
              </td>
            </tr>
            -->




        <tr onmouseout="place_stop()" onmouseover="place_start()">
          <td width="25%">
            <heading2><i>Publications</i></heading2><br><br>
            <div class="one">
                <div class="two" id="place_gif" style="opacity: 0;"><img src="./files/z_forcing" width=150 height=150></div>
                <img src="./files/z_forcing.png" width=150 height=150>
            </div>
            <script type="text/javascript">
            function place_start() {
              document.getElementById('place_gif').style.opacity = "1";
            }
   function place_stop() {
              document.getElementById('place_gif').style.opacity = "0";
            }
            place_stop()
            </script>

              </td>
              <td valign="top" width="75%">
                <heading2><i></i></heading2><br>
              <p><a href="">
                <papertitle>Z Forcing: Training Stochastic RNN's</papertitle></a><br>
              <strong>Anirudh Goyal*</strong>,
              Alessandro Sordoni*,
              Marc-Alexandre Côté,
              Rosemary Nan Ke,
              <a href="www.iro.umontreal.ca/~bengioy/yoshua_en/">Yoshua Bengio</a>,
              <em>Neural Information Processing System (NIPS)</em>, 2017 <br>
                <a href="">arXiv</a>
                /
                code (coming soon)
              </p><p></p>
              <p> 
              We proposed a novel approach to incorporate stochastic latent variables in sequential neural networks. The method builds on recent architectures that use latent variables to condition the recurrent dynamics of the network. We augmented the inference network with an RNN that runs backward through the sequence and added a new auxiliary cost that forces the latent variables to reconstruct the state of  that backward RNN, i.e. predict a summary of future observations.
              </p>
              </td>
            </tr>



        <tr onmouseout="maml_stop()" onmouseover="maml_start()">
          <td width="25%">
            <div class="one">
                <div class="two" id="maml_image" style="opacity: 0;"><img src="./files/vw.png" width=150 height=130></div>
                <img src="./files/vw.png" width=150 height=130>
            </div>
            <script type="text/javascript">
            function maml_start() {
              document.getElementById('maml_image').style.opacity = "1";
            }
   function maml_stop() {
              document.getElementById('maml_image').style.opacity = "0";
            }
            maml_stop()
            </script>

              </td>
              <td valign="top" width="75%">
              <p><a href="">
                <papertitle>Variational Walkback: Learning a Transition Operator as a Stochastic Recurrent Net</papertitle></a><br>
              <strong>Anirudh Goyal</strong>,
              Nan Rosemary Ke, 
              <a href="https://ganguli-gang.stanford.edu/surya.html">Surya Ganguli</a>,
              <a href="www.iro.umontreal.ca/~bengioy/yoshua_en/
              ">Yoshua Bengio</a> <br>
              <em>Neural Information Processing System (NIPS)</em>, 2017 <br>
                <a href="">arXiv</a>
                /
                blog post (coming soon)
                /
                code (coming soon)
              </p><p></p>
              <p> 
               We propose a novel method to directly learn a stochastic transition operator whose repeated application provides generated samples. Traditional undirected graphical models approach this problem indirectly by learning a Markov chain model whose stationary distribution obeys detailed balance with respect to a parameterized energy function.

              </p>
              </td>
            </tr>

      <tr onmouseout="sirfs_stop()" onmouseover="sirfs_start()">
          <td width="25%">
            <div class="one">
                <div class="two" id="sirfs_image" style="opacity: 0;"><img src="./files/sab.png" style="border-style: none" width="150"></div>
                <img src="./files/sab.png" style="border-style: none" width="150">
            </div>
            <script type="text/javascript">
            function sirfs_start() {
              document.getElementById('sirfs_image').style.opacity = "1";
            }
            function sirfs_stop() {
              document.getElementById('sirfs_image').style.opacity = "0";
            }
            sirfs_stop()
            </script>

          </td>
        <td width="75%" valign="top">
        <p>
          <a href="https://arxiv.org/pdf/1711.02326.pdf" id="SIRFS">
          <papertitle>Sparse Attentive BackTracking: Long Range Credit Assignment in Recurrent Networks</papertitle>
          </a>
          <br>
          Nan Rosemary Ke, <strong>Anirudh Goyal</strong>, Olexa Bilaniuk, Jonathan Binas, Laurent Charlin, Chris Pal, Yoshua Bengio <br>
          <em>ICML Workshop on Principled Approaches to Deep Learning</em>, 2017<br>
        </p>
        <p>
         We learns an attention mechanism
         over the hidden states in the past and selectively
         backpropagates through paths with high
         attention weight. This allows the model to learn
         long term dependencies while only backtracking
         for a small number of steps into the past. We think, its an efficient way of doing credit assignment in time.
        </p>
        </td>
      </tr>




        <tr onmouseout="ssrl_stop()" onmouseover="ssrl_start()">
          <td width="25%">

                  <heading2><i></i></heading2><br>
            <div class="one">
                <div class="two" id="ssrl_image" style="opacity: 0;"><img src="./files/zoneout.png" width=150 height=130></div>
                <img src="./files/zoneout.png" width=150 height=130>
            </div>
            <script type="text/javascript">
            function ssrl_start() {
              document.getElementById('ssrl_image').style.opacity = "1";
            }
            function ssrl_stop() {
              document.getElementById('ssrl_image').style.opacity = "0";
            }
            ssrl_stop()
            </script>

              </td>
              <td valign="top" width="75%">
              <p><a href="https://arxiv.org/abs/1606.01305">
                <papertitle>Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations</papertitle></a><br>
              David Krueger, Tegan Maharaj, Janos Kramar, Mohammad Pezeshki, Nicolas Ballas, Nan Rosemary Ke,<strong> Anirudh Goyal</strong>
              <a href="www.iro.umontreal.ca/~bengioy/yoshua_en/">Yoshua Bengio</a>,
              <a href="https://aaroncourville.wordpress.com/">Aaron Courville</a> <br>
              <a href="www.professeurs.polymtl.ca/christopher.pal/">Chris Pal</a> <br>
              <em>International Conference on Learning Representations (ICLR)</em>, 2017 <br> <!-- &nbsp; <font color="red"><strong>(Oral Presentation)</strong></font> <br-->
                <a href="https://arxiv.org/abs/1606.01305">arXiv</a>
                /
                <a href="https://github.com/teganmaharaj/zoneout">code</a>
              </p><p></p>
              <p>
              We propose zoneout, a novel method for regularizing RNNs. At each timestep, zoneout stochastically forces some hidden units to maintain their previous values. Like dropout, zoneout uses random noise to train a pseudo-ensemble, improving generalization. But by preserving instead of dropping hidden units, gradient information and state information are more readily propagated through time, as in feedforward stochastic depth networks. 
              </p>
              </td>
            </tr>



        <tr onmouseout="mpc_stop()" onmouseover="mpc_start()">
          <td width="25%">
            <div class="one">
                <div class="two" id="mpc_image" style="opacity: 0;"><img src="./files/actor_crticic.png" width=150 height=130></div>
                <img src="./files/actor_crticic.png" width=150 height=130>
            </div>
            <script type="text/javascript">
            function mpc_start() {
              document.getElementById('mpc_image').style.opacity = "1";
            }
            function mpc_stop() {
              document.getElementById('mpc_image').style.opacity = "0";
            }
            mpc_stop()
            </script>

              </td>
              <td valign="top" width="75%">
              <p><a href="">
                <papertitle>An Actor-Critic Algorithm for Sequence Prediction</papertitle></a><br>
                Dzmitry Bahdanau, Philemon Brakel, Kelvin Xu, <strong>Anirudh Goyal</strong>, Ryan Lowe, <a href="www.cs.mcgill.ca/~jpineau/">Joelle Pineau</a>,
              <a href="https://aaroncourville.wordpress.com/">Aaron Courville</a>,
              <a href="www.iro.umontreal.ca/~bengioy/yoshua_en/">Yoshua Bengio</a>
              <em>International Conference on Learning Representations (ICLR)</em>, 2017 <br> <!-- &nbsp; <font color="red"><strong>(Oral Presentation)</strong></font> <br-->
                <a href="https://arxiv.org/abs/1607.07086">arXiv</a>
                /
                <a href="https://github.com/rizar/actor-critic-public">code</a>
              </p><p></p>
              <p>
              We present an approach to training neural networks to generate sequences using actor-critic methods from reinforcement learning (RL). Current log-likelihood training methods are limited by the discrepancy between their training and testing modes, as models must generate tokens conditioned on their previous guesses rather than the ground-truth tokens. We address this problem by introducing a critic network that is trained to predict the value of an output token, given the policy of an actor network
              </p>
              </td>
            </tr>



        <tr onmouseout="rfgps_stop()" onmouseover="rfgps_start()">
          <td width="25%">
            <div class="one">
                <div class="two" id="rfgps_image" style="opacity: 0;"><img src="./files/pf_nips16.png" width=150 height=130></div>
                        <img src="./files/pf_nips16.png" width=150 height=130>
            </div>
            <script type="text/javascript">
            function rfgps_start() {
              document.getElementById('rfgps_image').style.opacity = "1";
            }
            function rfgps_stop() {
              document.getElementById('rfgps_image').style.opacity = "0";
            }
            rfgps_stop()
            </script>

              </td>
              <td valign="top" width="75%">
                <p><a href="https://papers.nips.cc/paper/6099-professor-forcing-a-new-algorithm-for-training-recurrent-networks.pdf">
                <papertitle>Professor Forcing: A New Algorithm for Training Recurrent Networks</papertitle></a><br>
              <strong>Anirudh Goyal</strong>, Alex Lamb, Ying Zhang, Saizheng Zhang, 
              <a href="https://aaroncourville.wordpress.com/">Aaron Courville</a>,
              <a href="www.iro.umontreal.ca/~bengioy/yoshua_en/">Yoshua Bengio</a>,
              <em> Neural Information on Processing System(NIPS)</em>, 2016 <br> <!-- &nbsp; <font color="red"><strong>(Oral Presentation)</strong></font> <br-->
                <a href="https://arxiv.org/abs/1610.09038">arXiv</a>
                /
                <a href="http://videolectures.net/deeplearning2016_goyal_new_algorithm/">video</a>
                /
                <a href="https://github.com/anirudh9119/LM_GANS">code</a>
              </p><p></p>
              <p>
              The Teacher Forcing algorithm trains recurrent networks by supplying observed sequence values as inputs during training and using the network’s own one-step-ahead predictions to do multi-step sampling. We introduce the Professor Forcing algorithm, which uses adversarial domain adaptation to encourage the dynamics of the recurrent network to be the same when training the network and when sampling from the network over multiple time steps.
              </p>
              </td>
            </tr>



      </tbody></table>

    </td>
    </tr>
  </tbody></table>


</body></html>
