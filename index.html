<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<!-- saved from url=(0041)https://people.eecs.berkeley.edu/~barron/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 16px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    heading2 {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 18px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 42px;
    }
    li:not(:last-child) {
        margin-bottom: 5px;
    }
    .one
    {
    width: 200px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 200px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <title>Nan Rosemary Ke</title>

  <link href="./_files/css" rel="stylesheet" type="text/css">
  <style id="dark-reader-style" type="text/css">@media screen {

/* Leading rule */
html {
  -webkit-filter: brightness(110%) contrast(90%) grayscale(20%) sepia(10%) !important;
}

/* Text contrast */
html {
  text-shadow: 0 0 0 !important;
}

/* Full screen */
*:-webkit-full-screen, *:-webkit-full-screen * {
  -webkit-filter: none !important;
}

/* Page background */
html {
  background: rgb(255,255,255) !important;
}

}</style></head>
  <body><div id="StayFocusd-infobar" style="display: none; top: 2400px;">
    <img src="chrome-extension://laankejkbhbdhmipfmgcngdelahlfoji/common/img/eye_19x19_red.png">
    <span id="StayFocusd-infobar-msg"></span>
    <span id="StayFocusd-infobar-links">
        <a id="StayFocusd-infobar-never-show">hide forever</a>&nbsp;&nbsp;|&nbsp;&nbsp;
        <a id="StayFocusd-infobar-hide">hide once</a>
    </span>
</div>
  <table width="1000" border="0" align="center" cellspacing="0" cellpadding="0">
    <tbody><tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td width="80%" valign="middle">
        <p align="center">
        <name>Nan Rosemary Ke</name><br>
        rosemary.nan.ke at gmail dot com
        </p>
        <p>I am a senior research scientist at <a href="https://deepmind.google/">Google Deepmind</a>. I completed my PhD at <a href="https://mila.quebec/en/">Mila</a>  with Professors <a href="https://mila.quebec/en/yoshua-bengio/">Yoshua Bengio</a> and <a href="https://mila.quebec/en/person/pal-christopher/">Chris Pal</a>.</p> 

</p>My research lies at the intersection of causal learning and deep learning. Causal models generalize probabilistic models by adding the capability to infer cause-and-effect relationships among variables and events. Traditional statistical methods for causal learning have difficulties handling latent variables, complex nonlinear relationships and do not scale well. Deep learning systems are increasingly being asked to answer questions that are essentially causal in nature. What is the causal effect of an agent's action on the state of the world and its ability to reach a goal? Which genes cause a disease? How does the content on a social media site or chatbot affect the views and behaviours of its users?
While deep learning is a powerful tool, it can only answer these questions reliably if it is used in a way that has a  causal grounding. My goal is to exploit synergies between causal learning and deep learning, obtaining the inferential strength of causal mechanisms with the scalability and representational capabilities of deep learning. These hybrid models will pave the way for more reliable, robust, and contextually aware AI systems, and provide tools for applications in diverse fields such as biology, medicine, healthcare, and psychology.</p>
  <p>
During my PhD, I have spent time at <a href="https://deepmind.com/">Google Deepmind</a>,  <a href="https://research.fb.com/category/facebook-ai-research/">Facebook AI Research</a>  and <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-montreal/">Microsoft Research</a>.
       </p>
    <p>
    I have recently been named a <a href="https://ml.umd.edu/rising-stars"> Rising Star in Machine Learning</a>.
	I have been awarded the <a href="https://research.fb.com/blog/2019/01/announcing-the-2019-facebook-fellows-and-emerging-scholars/">Facebook fellowship</a> in 2019.
        </p>
        <p align="center">
            <a href="https://scholar.google.ca/citations?user=dxwPYhQAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
	    <a href="https://github.com/nke001"> GitHub </a> &nbsp;/&nbsp;
	    <a href="https://twitter.com/rosemary_ke"> Twitter </a>
        </p>
        </td>
        <td  width=250 height=250>
        <img src="./files/img.jpg"  width=250 height=250>
        </td>
      </tr>
  </tbody></table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr><td>
            <heading>News</heading>
	    <ul>
          <li> At <a href="https://icml.cc/virtual/2020">ICML 2020</a>, we organized a workshop on <a href="https://biases-invariances-generalization.github.io/">Inductive Biases, Invariances and Generalization in RL</a>. </li>
	      <li> At <a href="https://iclr.cc/Conferences/2020">ICLR 2020</a>, we organized a workshop on <a href="https://causalrlworkshop.github.io/">Causal Learning for decision making</a>.</li>
	      <li> At <a href="http://www.cosyne.org/c/index.php?title=Cosyne_20">Cosyne 2020</a>, we organized a workshop on <a href="https://sites.google.com/view/memorymodularityattention/home">Memory, Modularity and Attentiong</a>.</li>
	      <li> Our paper <a href="https://arxiv.org/abs/2008.09301">Amortized learning of neural causal representations</a> which introduces a novel neural network architecture for learning a fully continous representation of causal models is now on arxiv.  </li>
          <li> Our paper <a href="https://arxiv.org/abs/1910.01075">learning neural causal models from unknown interventions</a> using continuous optimization is now on arxiv.  </li>
	      <!--	<li> At <a href="https://icml.cc/Conferences/2018/">ICML 2018</a>, I co-organized a workshop <a href="https://mltrain.cc/events/enabling-reproducibility-in-machine-learning-mltrainrml-icml-2018/">Workshop on Reproducibility in Machine Learning</a>.</li>
                <li> Our paper <a href="https://papers.nips.cc/paper/7991-sparse-attentive-backtracking-temporal-credit-assignment-through-reminding.pdf">"Sparse Attentive Backtracking: Temporal Credit Assignment Through Reminding” </a></li> received the Nvidia Poineer Award at NeurIPS 2018.  
              <li> At <a href="https://icml.cc/Conferences/2018/">ICML 2018</a>, I co-organized a workshop <a href="https://sites.google.com/view/creditassignmentindlanddrl/home">Workshop on Credit Assignment in Deep Learning and Deep Reinforcement Learning</a>.</li>
	      -->
              <!-- <li> At <a href="www.iclr.cc">ICLR 2018</a>, I co-organized the <a href="http://www.cs.mcgill.ca/~jpineau/ICLR2018-ReproducibilityChallenge.html">ICLR Reproducibility Challenge</a>.</li>

              <li> At <a href="https://icml.cc/Conferences/2017/">ICML 2017</a>, I co-organize a workshop <a href="https://sites.google.com/view/icml-reproducibility-workshop/home">Workshop on Reproducibility in Machine Learning</a>.</li>
              <li> At <a href="https://mila.quebec/en/cours/deep-learning-summer-school-2017/">Deep Learning and Reinforcement Learning Summer School</a>, I founded and co-organized the <a href="">Women in Deep Learning Workshop,</a>.</li> 
	      -->
	    </ul>
        </td></tr>

        <tr><td>
            <heading>Talks</heading>
            <ul>
        <li> I gave an invited talk at CogX 2020 on <a href="https://cogx.co/speakers/rosemary-nan-ke/">"Causality in Deep Learning” </a> to discuss how to incorrporate causality with deep learning to achieve better systematic generalization. </li>
		<li> I gave a talk at "Theory of deep learning: where next". IAS, Princeton University, on our recent work <a href="https://video.ias.edu/theorydeeplearning/2019/1017-Various"> "Learning Neural causal model under unknown interventions” </a>.</li>
        <li> I gave a talk at Nvidia GTC 2019 on <a href="https://www.facebook.com/nipsfoundation/videos/session-2-room-220-cd/1914579825246403/">"Sparse Attentive Backtracking: Temporal Credit Assignment Through Reminding” </a></li>
        <li> I gave a spotlight talk at NeurIPS 2018 on <a href="https://www.facebook.com/nipsfoundation/videos/1914579825246403">"Sparse Attentive Backtracking: Temporal Credit Assignment Through Reminding” </a></li>
        
        <!--<li> At ICML 2018, I gave a talk on my recent work <a href="https://videoken.com/embed/KAuEIw9dd0w">”Focused Hierarchical RNNs for Conditional Sequence Processing” </a></li>
                <li> In Oct 2017, I gave a talk on my work:<a href="https://openreview.net/pdf?id=BydLzGb0Z">”Twin Networks: Using the Future to generate sequences”</a></li>
              	<li> In Sep 2017, I gave a talk on my work: ””Hierachical Attention for sequence to sequence networks” at the Deep Language Workshop organized by MILA and Microsoft Research</a>. </li>
             	<li> In Jun 2017, I gave a talk on my work:<a href="https://arxiv.org/pdf/1711.04755.pdf">”ACTUAL: Actor-Critic Under Adversarial Learning”</a> at the Deep Learning and Reinforcement Leanrning Summer School</li>
              	<li> In Jun 2017, I gave a talk on my work:<a href="https://arxiv.org/pdf/1711.04755.pdf">”Hierachical Attention for sequence to sequence networks”,”</a> at the Samsung Workshop at University of Montreal</li>
              	<li> In Aug 2016, I gave an invited talk on <a href="https://www.perimeterinstitute.ca/videos/deep-learning-overview">”Deep Learning: An Overview”</a> at the Quantumn Machine Learning Workshop at Priemeter Insitute for Theoretical Physics</li>
             
              <li> In Sep 2016, I gave a talk on my work:<a href="https://arxiv.org/pdf/1711.04755.pdf">”Reviving the past: Training undirected graphical models”</a> at the 5th IBM ResearchCognitive Colloquium</li>
            -->    
        </ul>
        </td></tr>

      <tr>
        <td width="100%" valign="middle">
          <heading>Research</heading>
          <p>
        I am interested in developing novel machine learning algorithms that an generalize well to changing environments by improving credit assignment and encouraging causal learning in deep neural networks.
          </p>

        </td>
      </tr>
     </tbody></table>

     <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

       <!--
        <tr onmouseout="maml_stop()" onmouseover="maml_start()">
          <td width="25%">
            <heading2><i>Recent Preprints</i></heading2><br><br>
            <div class="one">
                <div class="two" id="maml_image" style="opacity: 0;"><img src="./_files/maml_diagram.png" width=150 height=140></div>
                <img src="./_files/maml_diagram.png" width=150 height=140>
            </div>
            <script type="text/javascript">
            function maml_start() {
              document.getElementById('maml_image').style.opacity = "1";
            }
   function maml_stop() {
              document.getElementById('maml_image').style.opacity = "0";
            }
            maml_stop()
            </script>

              </td>
              <td valign="top" width="75%">
                <heading2><i></i></heading2><br>
              <p><a href="https://arxiv.org/pdf/1703.03400.pdf">
                <papertitle>Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks</papertitle></a><br>
              <strong>Chelsea Finn</strong>,
              <a href="http://people.eecs.berkeley.edu/~pabbeel">Pieter Abbeel</a>,
              <a href="http://people.eecs.berkeley.edu/~svlevine">Sergey Levine</a> <br>
                <a href="https://arxiv.org/abs/1703.03400">arXiv</a>
                /
                <a href="https://github.com/cbfinn/maml">code</a>
                /
                <a href="https://sites.google.com/view/maml">video results</a>
              </p><p></p>
              <p> We propose a model-agnostic algorithm for meta-learning, where a model's parameters
              are trained such that a small number of gradient updates with a small amount of training data from a new task
              will produce good generalization performance on that task. Our method learns a classifier that can recognize
              images of new characters using only a few examples, and a policy that can rapidly adapt
              its behavior in simulated locomotion tasks.


              </p>
              </td>
            </tr>
            -->
        <tr onmouseout="maml_stop()" onmouseover="maml_start()">
          <td width="30%">
            <div class="one">
                <div class="two" id="maml_image" style="opacity: 0;"><img src="./files/sab.png" width=150 height=130></div>
                <img src="./files/sab.png" width=150 height=130>
            </div>
            <script type="text/javascript">
            function maml_start() {
              document.getElementById('maml_image').style.opacity = "1";
            }
   function maml_stop() {
              document.getElementById('maml_image').style.opacity = "0";
            }
            maml_stop()
            </script>

            </td>
              <td valign="top" width="75%">
              <p><a href="https://arxiv.org/pdf/1809.03702.pdf">
                <papertitle>Sparse Attentive Backtracking: Temporal Credit Assignment Through Reminding</papertitle></a><br>
              <strong>Nan Rosemary Ke</strong>,
              Anirudh Goyal, Olexa Blanik, Jonathan Binas, Michael Mozer, Chris Pal, Yoshua Bengio


              <em>The Thirty-second Annual Conference on Neural Information Processing Systems (NeuIPS) <strong>Spotlight presentation</strong> </em>, 2018 <br>
              <a href="">Arxiv</a>
                /
                blog post (coming soon)
                /
              </p><p></p>
              <p>
              Learning long-term dependencies in extended temporal sequences requires credit assignment to events far back in the past. The most common method for training recurrent neural networks, back-propagation through time (BPTT), requires credit information to be propagated backwards through every single step of the forward computation, potentially over thousands or millions of time steps.
              This becomes computationally expensive or even infeasible when used with long sequences. Importantly, biological brains are unlikely to perform such detailed reverse replay over very long sequences of internal states (consider days, months, or years.) However, humans are often reminded of past memories or mental states which are associated with the current mental state.
              We consider the hypothesis that such memory associations between past and present could be used for credit assignment through arbitrarily long sequences, propagating the credit assigned to the current state to the associated past state. Based on this principle, we study a novel algorithm which only back-propagates through a few of these temporal skip connections, realized by a learned attention mechanism that associates current states with relevant past states. We demonstrate in experiments that our method matches or outperforms regular BPTT and truncated BPTT in tasks involving particularly long-term dependencies, but without requiring the biologically implausible backward replay through the whole history of states. Additionally, we demonstrate that the proposed method transfers to longer sequences significantly better than LSTMs trained with BPTT and LSTMs trained with full self-attention.
              </p>
              </td>
    </tr>
    
	  
	    
    <tr onmouseout="sirfs_stop()" onmouseover="sirfs_start()">
          <td width="30%">

            <heading2><i>Publications</i></heading2><br><br>
             <div class="one">
                <div class="two" id="sirfs_image" style="opacity: 0;"><img src="./files/sab.png" style="border-style: none" width="150"></div>
                <img src="./files/sab.png" style="border-style: none" width="150">
            </div>
            <script type="text/javascript">
            function sirfs_start() {
              document.getElementById('sirfs_image').style.opacity = "1";
            }
            function sirfs_stop() {
              document.getElementById('sirfs_image').style.opacity = "0";
            }
            sirfs_stop()
            </script>


              </td>
              <td valign="top" width="75%">
              <p><a href="http://proceedings.mlr.press/v80/ke18a.html">
                <papertitle>Focused Hierarchical RNNs for Conditional Sequence Processing</papertitle></a><br>
              <strong>Nan Rosemary Ke</strong>,
              Konrad Zolna, Alessandro Sordoni, Zhouhan Lin, Adam Trischler, Yoshua Bengio, Joelle Pineau, Laurent Charlin, Chris Pal
              
              
              <em>International Conference on Machine Learning (ICML)</em>, 2018 <br>
              <a href="http://proceedings.mlr.press/v80/ke18a.html">Arxiv</a>
                /
                blog post (coming soon)
                /
              </p><p></p>
              <p>
                We present a mechanism for focusing RNN encoders for sequence modelling tasks which allows them to attend to key parts of the input as needed. We formulate this using a multilayer conditional sequence encoder that reads in one token at a time and makes a discrete decision on whether the token is relevant to the context or question being asked. The discrete gating mechanism takes in the context embedding and the current hidden state as inputs and controls information flow into the layer above.
              </p>
              </td>
    </tr>


    <tr onmouseout="sirfs_stop()" onmouseover="sirfs_start()">
          <td width="30%">
            
            
              <div class="one">
                <div class="two" id="sirfs_image" style="opacity: 0;"><img src="./files/twin.png" style="border-style: none" width="150"></div>
                <img src="./files/twin.png" style="border-style: none" width="150">
            </div>
            <script type="text/javascript">
            function sirfs_start() {
              document.getElementById('sirfs_image').style.opacity = "1";
            }
            function sirfs_stop() {
              document.getElementById('sirfs_image').style.opacity = "0";
            }
            sirfs_stop()
            </script>

          </td>
        <td width="75%" valign="top">
        <p>
          <a href="https://openreview.net/pdf?id=BydLzGb0Z" id="SIRFS">
          <papertitle>Twin Networks: Using the future to generate sequences</papertitle>
          </a>
          <br>
          <strong>Nan Rosemary Ke*</strong>, Dmitry Serdyuk*, Alessandro Sordoni, Adam Trischler, Chris Pal, Yoshua Bengio <br>
          <em>International Conference on Learning Representations (ICLR)</em>, 2018<br>
        </p>
        <p>
        We propose a simple technique for encouraging generative RNNs to plan ahead.  We train a “backward” recurrent network to generate a given sequence in reverse
order, and we encourage states of the forward model to predict cotemporal states
of the backward model. The backward network is used only during training, and
plays no role during sampling or inference. We hypothesize that our approach
eases modeling of long-term dependencies by implicitly forcing the forward states
to hold information about the longer-term future (as contained in the backward
states). 
        </p>
        </td>
    </tr>
 
    

    <tr onmouseout="place_stop()" onmouseover="place_start()">
          <td width="30%">
            <div class="one">
                <div class="two" id="place_gif" style="opacity: 0;"><img src="./files/z_forcing" width=150 height=150></div>
                <img src="./files/z_forcing.png" width=150 height=150>
            </div>
            <script type="text/javascript">
            function place_start() {
              document.getElementById('place_gif').style.opacity = "1";
            }
   function place_stop() {
              document.getElementById('place_gif').style.opacity = "0";
            }
            place_stop()
            </script>

              </td>
              <td valign="top" width="75%">
                <heading2><i></i></heading2><br>
              <p><a href="https://arxiv.org/pdf/1711.05411.pdf">
                <papertitle>Z Forcing: Training Stochastic RNN's</papertitle></a><br>
              Anirudh Goyal,
              Alessandro Sordoni,
              Marc-Alexandre Côté,
              <strong>Rosemary Nan Ke</strong>,
              <a href="www.iro.umontreal.ca/~bengioy/yoshua_en/">Yoshua Bengio</a>,
              <em>Neural Information Processing System (NIPS)</em>, 2017 <br>
                <a href="">arXiv</a>
                /
                code (coming soon)
              </p><p></p>
              <p> 
              We proposed a novel approach to incorporate stochastic latent variables in sequential neural networks. The method builds on recent architectures that use latent variables to condition the recurrent dynamics of the network. We augmented the inference network with an RNN that runs backward through the sequence and added a new auxiliary cost that forces the latent variables to reconstruct the state of  that backward RNN, i.e. predict a summary of future observations.
              </p>
              </td>
            </tr>



        <tr onmouseout="maml_stop()" onmouseover="maml_start()">
          <td width="30%">
            <div class="one">
                <div class="two" id="maml_image" style="opacity: 0;"><img src="./files/vw.png" width=150 height=130></div>
                <img src="./files/vw.png" width=150 height=130>
            </div>
            <script type="text/javascript">
            function maml_start() {
              document.getElementById('maml_image').style.opacity = "1";
            }
   function maml_stop() {
              document.getElementById('maml_image').style.opacity = "0";
            }
            maml_stop()
            </script>

              </td>
              <td valign="top" width="75%">
              <p><a href="https://papers.nips.cc/paper/7026-variational-walkback-learning-a-transition-operator-as-a-stochastic-recurrent-net">
                <papertitle>Variational Walkback: Learning a Transition Operator as a Stochastic Recurrent Net</papertitle></a><br>
              Anirudh Goyal,
              <strong>Nan Rosemary Ke</strong>, 
              <a href="https://ganguli-gang.stanford.edu/surya.html">Surya Ganguli</a>,
              <a href="www.iro.umontreal.ca/~bengioy/yoshua_en/
              ">Yoshua Bengio</a> <br>
              <em>Neural Information Processing System (NIPS)</em>, 2017 <br>
                <a href="https://arxiv.org/pdf/1711.02282.pdf">arXiv</a>
                /
                blog post (coming soon)
                /
                <a href="https://github.com/anirudh9119/walkback_nips17">code</a> 
              </p><p></p>
              <p> 
               We propose a novel method to directly learn a stochastic transition operator whose repeated application provides generated samples. Traditional undirected graphical models approach this problem indirectly by learning a Markov chain model whose stationary distribution obeys detailed balance with respect to a parameterized energy function.

              </p>
              </td>
            </tr>


        <tr onmouseout="ssrl_stop()" onmouseover="ssrl_start()">
          <td width="30%">

                  <heading2><i></i></heading2><br>
            <div class="one">
                <div class="two" id="ssrl_image" style="opacity: 0;"><img src="./files/chatbot.png" width=150 height=130></div>
                <img src="./files/chatbot.png" width=150 height=130>
            </div>
            <script type="text/javascript">
            function ssrl_start() {
              document.getElementById('ssrl_image').style.opacity = "1"; 
            }   
            function ssrl_stop() {
              document.getElementById('ssrl_image').style.opacity = "0";
            } 
            ssrl_stop()
            </script>

              </td>
              <td valign="top" width="75%">
              <p><a href="https://arxiv.org/pdf/1709.02349.pdf">
                <papertitle>A Deep Reinforcement Learning Chatbot</papertitle></a><br>
            Iulian V. Serban, Chinnadhurai Sankar, Mathieu Germain, Saizheng Zhang, Zhouhan Lin,
Sandeep Subramanian, Taesup Kim, Michael Pieper, Sarath Chandar, <strong> Nan Rosemary Ke</strong>,
Sai Rajeshwar, Alexandre de Brebisson, Jose M. R. Sotelo, Dendi Suhubdy,
Vincent Michalski, Alexandre Nguyen, Joelle Pineau and <a href="www.iro.umontreal.ca/~bengioy/yoshua_en/">Yoshua Bengio</a>,
              <em>International Conference on Learning Representations (ICLR)</em>, 2017 <br> <!-- &nbsp; <font color="red"><strong>(Oral Presentation)</strong></font> <br-->
                <a href="https://arxiv.org/abs/1606.01305">arXiv</a>
              </p><p></p>
              <p>
              We present MILABOT: a deep reinforcement learning chatbot developed by the Montreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize competition. MILABOT is capable of conversing with humans on popular small talk topics through both speech and text. The system consists of an ensemble of natural language generation and retrieval models, including template-based models, bag-of-words models, sequence-to-sequence neural network and latent variable neural network models. By applying reinforcement learning to crowdsourced data and real-world user interactions, the system has been trained to select an appropriate response from the models in its ensemble. The system has been evaluated through A/B testing with real-world users, where it performed significantly better than many competing systems. Due to its machine learning architecture, the system is likely to improve with additional data.
              </p>
              </td>
            </tr>


        <tr onmouseout="ssrl_stop()" onmouseover="ssrl_start()">
          <td width="30%">

                  <heading2><i></i></heading2><br>
            <div class="one">
                <div class="two" id="ssrl_image" style="opacity: 0;"><img src="./files/zoneout.png" width=150 height=130></div>
                <img src="./files/zoneout.png" width=150 height=130>
            </div>
            <script type="text/javascript">
            function ssrl_start() {
              document.getElementById('ssrl_image').style.opacity = "1";
            }
            function ssrl_stop() {
              document.getElementById('ssrl_image').style.opacity = "0";
            }
            ssrl_stop()
            </script>

              </td>
              <td valign="top" width="75%">
              <p><a href="https://arxiv.org/abs/1606.01305">
                <papertitle>Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations</papertitle></a><br>
            David Krueger, Tegan Maharaj, Janos Kramar, Mohammad Pezeshki, Nicolas Ballas,<strong>Nan Rosemary Ke</strong>, Anirudh Goyal
              <a href="www.iro.umontreal.ca/~bengioy/yoshua_en/">Yoshua Bengio</a>,
              <a href="https://aaroncourville.wordpress.com/">Aaron Courville</a> <br>
              <a href="www.professeurs.polymtl.ca/christopher.pal/">Chris Pal</a> <br>
              <em>International Conference on Learning Representations (ICLR)</em>, 2017 <br> <!-- &nbsp; <font color="red"><strong>(Oral Presentation)</strong></font> <br-->
                <a href="https://arxiv.org/abs/1606.01305">arXiv</a>
                /
                <a href="https://github.com/teganmaharaj/zoneout">code</a>
              </p><p></p>
              <p>
              We propose zoneout, a novel method for regularizing RNNs. At each timestep, zoneout stochastically forces some hidden units to maintain their previous values. Like dropout, zoneout uses random noise to train a pseudo-ensemble, improving generalization. But by preserving instead of dropping hidden units, gradient information and state information are more readily propagated through time, as in feedforward stochastic depth networks. 
              </p>
              </td>
            </tr>

   <tr onmouseout="ssrl_stop()" onmouseover="ssrl_start()">
          
	   <!--<td width="30%">
            <heading2><i></i></heading2><br>
            <div class="one">
                <div class="two" id="ssrl_image" style="opacity: 0;"><img src="./files/bandit.png" width=150 height=130></div>
                <img src="./files/bandit.png" width=150 height=130>
            </div>
            <script type="text/javascript">
            function ssrl_start() {
              document.getElementById('ssrl_image').style.opacity = "1";
            }
            function ssrl_stop() {
              document.getElementById('ssrl_image').style.opacity = "0";
            }
            ssrl_stop()
            </script>

              </td>
              
	      <td valign="top" width="75%">
              <p><a href="https://arxiv.org/pdf/1603.05359.pdf">
                <papertitle>Cascading Bandits for Large-Scale Recommendation Problems</papertitle></a><br>
            Shi Zong, Hao Ni, Kenny Sung, <strong>Nan Rosemary Ke</strong>, Zheng Wen, Branislav Kveton
	    <em>Association for Uncertainty in Artificial Intelligence (UAI)</em>, 2016 <br> --> <!-- &nbsp; <font color="red"><strong>(Oral Presentation)</strong></font> <br-->
              <!--  <a href="https://arxiv.org/pdf/1603.05359.pdf">arXiv</a>
              </p><p></p>
              <p>
             Most recommender systems recommend a list of items. The user examines the list, from the first item to the last, and often chooses the first attractive item and does not examine the rest. This type of user behavior can be modeled by the cascade model. In this work, we study cascading bandits, an online learning variant of the cascade model where the goal is to recommend K most attractive items from a large set of L candidate items. We propose two algorithms for solving this problem, which are based on the idea of linear generalization. The key idea in our solutions is that we learn a predictor of the attraction probabilities of items from their features, as opposing to learning the attraction probability of each item independently as in the existing work. This results in practical learning algorithms whose regret does not depend on the number of items L. We bound the regret of one algorithm and comprehensively evaluate the other on a range of recommendation problems. The algorithm performs well and outperforms all baselines 
            </p>
              </td>
            </tr>
	    -->
      </tbody></table>

    </td>
    </tr>
  </tbody></table>


</body></html>
